---
title: ' Predicting Activities'
output:
  html_document:
    fig_caption: yes
    keep_md: yes
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,cache=TRUE)
library(plyr)
library(caret)
library(doParallel)
cl <- makeCluster(detectCores())
registerDoParallel(cl)


```
### Introduction
This is a R Markdown document for the assignment titled "Predicting Activities". The document would include exploratory analysis of the data and using K-fold method for cross-validation approach.The developed model would be used to predict 20 cases from the actual test data. The seed was set as system default

### Exploratory
This portion of the code that reads on the data from csv inputs. 
```{r toruncode}
training<-read.csv(file="pml-training.csv")
testing<-read.csv(file="pml-testing.csv")
```
### Training

This portion of the code does the training part and some processing before the model is trained to predict different classes. There are different techniques employed to fully understand the advantage of using the Cross-validation approach to obtained the best averaged model to predicting the outcomes.

Firstly, the index for the entries are removed from both the training and testing data set. There are a number of NA entries in training data set and they were removed. 

The first model was trained with cross-validation with fold of 30. This means that the data was spitted into 30 different groups and out of each group one of the sample was used for testing. This was implemented on the training data with the random forest to compare the improvement in accuracy. It is to note that the training was implemented with parallel cluster on a multi-core machine due to the large number of predictors involved.

The predictors with NA values from the test data set were removed and the same was done for the training data-set. 


```{r Filtering}
train_control <- trainControl(method="cv", number=30)
training2<-na.omit(training[,c(-1)])
testing2<-testing[,c(-1)]  
#Filtering away data that is not useful,Cols with NA)
testing2_fil<-data.frame(t(na.omit(t(testing2))))
da<-c(names(testing2_fil))
trainingfi<-training2[,c(da[1:58],"classe")]
testing_final<-testing2_fil[,c(da[1:58])]
```


```{r training cv}
trainmod_cv<-train(classe~.,method="rf",trControl=train_control,na.action = na.exclude,data=trainingfi)
```

```{r training rf}
trainmod_rf<-train(classe~.,method="rf",na.action = na.exclude,data=trainingfi)
```

*Accuracy from using the cross-validation approach yielded accuracy of 0.8975885 vs 0.8169673 for the non cross-validation approach.*

### Analysing model
This portion of the code looks at the important predictors from the CV and RF models.
```{r results}
trainmod_rf
trainmod_cv
trainpre_rf<-predict(trainmod_rf,training2)
trainpre_cv<-predict(trainmod_cv,training2)
confusionMatrix(trainpre_cv,training2$classe)
confusionMatrix(trainpre_rf,training2$classe)
```
The Confusion matrices show that the models from both the RF and 30 fold using cross validation. The results looks very good with perfect agreement for every class for the training set. 

### Predicting the classes
```{r Prediction}
cv_real<-predict(trainmod_rf,testing2)
cv_real
```